{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf2cc852",
   "metadata": {},
   "source": [
    "---\n",
    "layout: post\n",
    "title:  \"Markov Decision Process\"\n",
    "date:   2023-03-13 10:14:54 +0700\n",
    "categories: jekyll update\n",
    "---\n",
    "\n",
    "# TOC\n",
    "\n",
    "- [Definition](#define)\n",
    "- [Example](#ex)\n",
    "- [Code example](#code)\n",
    "\n",
    "# Definition <a name=\"#define\"></a>\n",
    "\n",
    "A Markov decision process is an agent that has access to the following information:\n",
    "\n",
    "- state space S\n",
    "\n",
    "- action set A in each state s\n",
    "\n",
    "- transition probabilities P over the state space at each state (i.e. from one state we know the probability to end up in the next state if we take action a)\n",
    "\n",
    "- discount factor $$ \\gamma $$ to discount future cashflow\n",
    "\n",
    "- reward function R over the action a and the state s it ends up in\n",
    "\n",
    "A policy is to map each state to an action. The utility of a policy is the discounted sum of all the rewards on the path of that policy. We discount the value of tomorrow so that money of today worths a bit more than that same amount tomorrow. Here is the discounted sum:\n",
    "\n",
    "$$ u = r_1 + \\gamma r_2 + \\gamma^2 r_3 + ... $$\n",
    "\n",
    "The value of a policy at a state is the expected utility $$ V_{\\pi}(s) $$. The Q-value $$ Q_{\\pi} (s,a) $$ is the expected utility of taking action a at state s, and then following policy $$ \\pi $$. Value at s is either equals 0 (if it is the end), or equals its Q-value otherwise, with Q-value to be the total of probable transitions to all the s' multiplied with its discounted cashflow:\n",
    "\n",
    "$$ V_{\\pi}(s) =\n",
    "\\begin{cases}\n",
    "    0 & \\text{if s ends} \\\\\n",
    "    Q_{\\pi}(s,\\pi(s)) & \\text{otherwise} \\\\\n",
    "\\end{cases}\n",
    "$$ \n",
    "\n",
    "with $$ Q_{\\pi}(s,a)=\\sum_{s'} P(s,a,s') E{[R(s,a,s') + \\gamma V_{\\pi} (s')]} $$ (Q-value equals probabilities multiplied by expected value). To evaluate policy, we initialize values at all states to be 0:\n",
    "\n",
    "$$ V_{\\pi}^{(0)} \\leftarrow 0 $$ \n",
    "\n",
    "Then for each iteration:\n",
    "\n",
    "$$ V_{\\pi}^{(t)}(s) \\leftarrow Q^{t-1}(s,\\pi(s)) = \\sum_{s'} P(s,\\pi(s), s') E {[R(s,\\pi(s), s') + \\gamma V_{\\pi}^{(t-1)} (s')]} $$\n",
    "\n",
    "We iterate until:\n",
    "\n",
    "$$ max_{s \\in S} \\mid V_{\\pi}^{(t)} (s) - V_{\\pi}^{(t-1)}(s) \\mid \\leq \\epsilon $$\n",
    "\n",
    "The optimal value $$ V_{opt}(s) $$ is the maximum value for each policy. As above,\n",
    "\n",
    "$$ V_{opt}(s) =\n",
    "\\begin{cases}\n",
    "    0 & \\text{if s ends} \\\\\n",
    "    max_{a \\in A(s)} Q_{opt}(s,a) & \\text{otherwise} \\\\\n",
    "\\end{cases}\n",
    "$$ \n",
    "\n",
    "with $$ Q_{opt}(s,a)=\\sum_{s'} P(s,a,s') E{[R(s,a,s') + \\gamma V_{opt} (s')]} $$\n",
    "\n",
    "Following the similar vein, the optimal policy would be the one that maximize the Q-value with action a:\n",
    "\n",
    "$$ \\pi_{opt}(s) = arg max_{a \\in A(s)} Q_{opt}(s,a) $$\n",
    "\n",
    "Now we iterate for optimal value:\n",
    "\n",
    "- Initialize $$ V_{opt}^{(0)}(s) \\leftarrow 0 $$\n",
    "\n",
    "- For each state s: $$ V_{opt}^{(t)} \\leftarrow  max_{a \\in A(s)} Q_{opt}^{(t-1)} (s,a) =  max_{a \\in A(s)} \\sum_{s'} P(s,a,s') E{[R(s,a,s') + \\gamma V_{opt}^{(t-1)} (s')]} $$\n",
    "\n",
    "# Example <a name=\"#ex\"></a>\n",
    "\n",
    "We play a game. At each round, you choose to stay or quit. If you quit, you get $$ \\$10 $$ and ends the game. If you stay, you get $$ \\$4 $$ and $$ \\frac{1}{3} $$ probability of ending the game and $$ \\frac{2}{3} $$ probability of going to the next round. Let $$ \\gamma = 1 $$.\n",
    "\n",
    "There are two policies: to stay or to quit. The value of policy \"quit\" is $$ \\$10 $$. Let's evaluate the policy of \"stay\":\n",
    "\n",
    "$$ V_{\\pi} (end) = 0 $$\n",
    "\n",
    "$$ V_{\\pi}(in) = \\frac{1}{3} (4 + V_{\\pi} (end)) + \\frac{2}{3} (4 + V_{\\pi}(in)) = 4 + \\frac{2}{3} V_{\\pi}(in) $$\n",
    "\n",
    "$$ \\Leftrightarrow \\frac{1}{3} V_{\\pi}(in) = 4 $$\n",
    "\n",
    "$$ \\Leftrightarrow V_{\\pi}(in) = 12 > 10 $$\n",
    "\n",
    "We definitely should stay in the game.\n",
    "\n",
    "# Code example <a name=\"code\"></a>\n",
    "\n",
    "At time 0, we set value policy stay to be 0. At iteration 1, at state in, value (in) = Q-value at 0 = probabilities * expected utility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67732716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'count' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/kf/5_ggvsz93vxdbx_h0tvy66xh0000gn/T/ipykernel_12455/1063755070.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/kf/5_ggvsz93vxdbx_h0tvy66xh0000gn/T/ipykernel_12455/1063755070.py\u001b[0m in \u001b[0;36mf\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0miterate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/kf/5_ggvsz93vxdbx_h0tvy66xh0000gn/T/ipykernel_12455/1063755070.py\u001b[0m in \u001b[0;36miterate\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0miterate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Hello\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'count' referenced before assignment"
     ]
    }
   ],
   "source": [
    "import random\n",
    "    util = []\n",
    "    count = 0  \n",
    "def f():\n",
    "\n",
    "    r = random.randin(0,6)\n",
    "    if r < 2:\n",
    "        value += 4\n",
    "        util.append(value)\n",
    "    else:\n",
    "        value += f()\n",
    "        \n",
    "    while count < 50:\n",
    "        if util[count] - util[count-1] <= 0.001:\n",
    "            return value\n",
    "        else:\n",
    "            count += 1\n",
    "            r = random.randin(0,6)\n",
    "            if r < 2:\n",
    "                value += 4\n",
    "                util.append(value)\n",
    "            else:\n",
    "                value += iterate()\n",
    "    return util\n",
    "f()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "663d15c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.randint(0,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc95b0e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a437ef8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
