{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "872d97c6",
   "metadata": {},
   "source": [
    "---\n",
    "layout: post\n",
    "title:  \"Generative Adversarial Network\"\n",
    "date:   2023-03-22 10:14:54 +0700\n",
    "categories: jekyll update\n",
    "---\n",
    "\n",
    "# Introduction\n",
    "\n",
    "As the name suggests, GAN holds an adversarial relationship between two networks: a generator and a discriminator. The generator is a generative model that learns the data distribution of a population. Note that it doesn't learn directly, but via the prediction / classification / feedback of the discriminator. The discriminative model's job is to tell whether a sample comes from the data distribution or generated by the generator. A real world scenario for this framework is one in which the criminal tries to forge fake money and the police would need to tell fake from real money. In game theoretical framework, this is a two person zero sum game whose solution would be derived through minimax strategy: one tries to maximize his utility and the other tries to min it. There is a global solution in which the forgery looks the same as the real images/money (the generator learns the distribution), and the discriminator cannot tell the difference any more (the estimation of a sample to be fake is one half - effectively a random choice).\n",
    "\n",
    "## Training\n",
    "\n",
    "Initially, we input the correctly labeled images both from the generator and the data distribution to the discriminator, so that the discriminitor learns to predict with backpropagation. Training the generator is a bit more complicated since we need the feedback from the discriminator. So, we freeze the discriminator network, and use it as an agent of feedback. For the part of the generator, we input a random vector (from the space of all possibile vector for images - called the laten space) for the generator to output a fake image. This fake image is put through the discriminitor for classification, but we set the label for the fake image to be 1 (real). This is to maximize the mistake of the discriminator. The predicted result from the discriminator is put back to the generator so that the generator learns. This is roughly supervised learning. We use the cross entropy cost function between the discriminiator's $$ \\hat{y} $$ and y true. In tensorflow, for the fully connected version of the GAN, we use ReLU activation, He normal initialization, binary cross entropy loss and RMSProp optimizer.\n",
    "\n",
    "### Fully Connected GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d1321e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Dense = tf.keras.layers.Dense\n",
    "generator = tf.keras.Sequential([\n",
    "    Dense(100, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "    Dense(150, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "    Dense(28 * 28, activation=\"sigmoid\"),\n",
    "    tf.keras.layers.Reshape([28, 28])\n",
    "])\n",
    "discriminator = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(),\n",
    "    Dense(150, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "    Dense(100, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "gan = tf.keras.Sequential([generator, discriminator])\n",
    "\n",
    "discriminator.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")\n",
    "discriminator.trainable = False\n",
    "gan.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee8e18a",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Deep CNN GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4604e0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(7 * 7 * 128),\n",
    "    tf.keras.layers.Reshape([7, 7, 128]),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Conv2DTranspose(64, kernel_size=5, strides=2,\n",
    "                                    padding=\"same\", activation=\"relu\"),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Conv2DTranspose(1, kernel_size=5, strides=2,\n",
    "                                    padding=\"same\", activation=\"tanh\"),\n",
    "])\n",
    "discriminator = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, kernel_size=5, strides=2, padding=\"same\",\n",
    "                        activation=tf.keras.layers.LeakyReLU(0.2)),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Conv2D(128, kernel_size=5, strides=2, padding=\"same\",\n",
    "                        activation=tf.keras.layers.LeakyReLU(0.2)),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "gan = tf.keras.Sequential([generator, discriminator])\n",
    "\n",
    "discriminator.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")\n",
    "discriminator.trainable = False\n",
    "gan.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6f58c5",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Deeper CNN GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8632c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator(depth=64, p=0.4): # Define inputs\n",
    "    image = Input((img_w,img_h,1))\n",
    "    # Convolutional layers\n",
    "    conv1 = Conv2D(depth*1, 5, strides=2,\n",
    "                   padding='same', activation='relu')(image)\n",
    "    conv1 = Dropout(p)(conv1)\n",
    "    conv2 = Conv2D(depth*2, 5, strides=2,\n",
    "               padding='same', activation='relu')(conv1)\n",
    "    conv2 = Dropout(p)(conv2)\n",
    "    conv3 = Conv2D(depth*4, 5, strides=2,\n",
    "                   padding='same', activation='relu')(conv2)\n",
    "    conv3 = Dropout(p)(conv3)\n",
    "    conv4 = Conv2D(depth*8, 5, strides=1,\n",
    "               padding='same', activation='relu')(conv3)\n",
    "    conv4 = Flatten()(Dropout(p)(conv4))\n",
    "    # Output layer\n",
    "    \n",
    "    prediction = Dense(1, activation='sigmoid')(conv4)\n",
    "    # Model definition\n",
    "    model = Model(inputs=image, outputs=prediction) \n",
    "    return model\n",
    "discriminator = build_discriminator()\n",
    "discriminator.compile(loss='binary_crossentropy',\n",
    "                      optimizer=RMSprop(lr=0.0008, decay=6e-8,\n",
    "                                        clipvalue=1.0),\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "def build_generator(latent_dim=z_dimensions,\n",
    "                      depth=64, p=0.4):\n",
    "    noise = Input((latent_dim,))\n",
    "    # First dense layer\n",
    "    dense1 = Dense(7*7*depth)(noise)\n",
    "    dense1 = BatchNormalization(momentum=0.9)(dense1)\n",
    "    dense1 = Activation(activation='relu')(dense1)\n",
    "    dense1 = Reshape((7,7,depth))(dense1)\n",
    "    dense1 = Dropout(p)(dense1)\n",
    "    # De-Convolutional layers\n",
    "    conv1 = UpSampling2D()(dense1)\n",
    "    conv1 = Conv2DTranspose(int(depth/2),\n",
    "                            kernel_size=5, padding='same', activation=None,)(conv1) \n",
    "    conv1 = BatchNormalization(momentum=0.9)(conv1)\n",
    "    conv1 = Activation(activation='relu')(conv1)\n",
    "    conv2 = UpSampling2D()(conv1)\n",
    "    conv2 = Conv2DTranspose(int(depth/4),\n",
    "                            kernel_size=5, padding='same',\n",
    "                            activation=None,)(conv2) \n",
    "    conv2 = BatchNormalization(momentum=0.9)(conv2)\n",
    "    conv2 = Activation(activation='relu')(conv2)\n",
    "    conv3 = Conv2DTranspose(int(depth/8),\n",
    "                            kernel_size=5, padding='same',\n",
    "                            activation=None,)(conv2) \n",
    "    conv3 = BatchNormalization(momentum=0.9)(conv3)\n",
    "    conv3 = Activation(activation='relu')(conv3)\n",
    "    # Output layer\n",
    "    image = Conv2D(1, kernel_size=5, padding='same',\n",
    "                   activation='sigmoid')(conv3)\n",
    "    # Model definition\n",
    "    model = Model(inputs=noise, outputs=image) \n",
    "    return model\n",
    "\n",
    "generator = build_generator()\n",
    "\n",
    "img = generator(z) \n",
    "discriminator.trainable = False \n",
    "pred = discriminator(img) \n",
    "adversarial_model = Model(z, pred)\n",
    "\n",
    "adversarial_model.compile(loss='binary_crossentropy',\n",
    "                          optimizer=RMSprop(lr=0.0004, decay=3e-8,\n",
    "                                            clipvalue=1.0),\n",
    "                          metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f87d8a7",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## CIFAR-10"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
