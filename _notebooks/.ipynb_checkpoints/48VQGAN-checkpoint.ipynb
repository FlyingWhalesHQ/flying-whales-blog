{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8e05010",
   "metadata": {},
   "source": [
    "---\n",
    "layout: post\n",
    "title:  \"VQ-GAN\"\n",
    "date:   2023-06-15 10:14:54 +0700\n",
    "categories: DeepLearning\n",
    "---\n",
    "\n",
    "# Introduction\n",
    "\n",
    "VQ-GAN stands for Vector Quantized Generative Adversarial Network. It is a combination of two machine learning methodologies: vector quantization and generative adversarial network. GAN was developed with two neural networks: a generator and a discriminator. They are trained together and the generator trying to improve its realistic generation and the discriminator improving its ability to spot fake generation. Vector quantization is a technique used in lossy data compression where large vectors are approximated by a finite set of smaller vectors. Each vector from the large set is mapped to one of the smaller ones. And the smaller vectors are called the codebook. In VQ-GAN, the VQ layer is like a lookup table, which maps continuous inputs (images) into a discrete set of outputs. These outputs can then be put through a transformer. And that constitutes the generator part. DALL-E from OpenAI uses a form of VQ-GAN to generate images from textual descriptions.\n",
    "\n",
    "VQ-GAN is composed of several building blocks: a VQ-VAE-2 encoder, an image transformer, and a discriminator. The VQ-VAE-2 is a vector quantized variational auto encoder that compress the input image into discrete latent space. The image transformer is used to generate in the discrete latent space, to reduce computational complexity. Then we can sample from this codebook (discrete latent space) to generate new images. Since the latent space is the one that can maintain the patterns in the images, it also maintains spatial coherence and semantics of the generated images. Note that VQ-GAN makes use of transformer, instead of usual convolutional neural network counterpart. Transformer has shown superior performance in many settings to CNN. However, it is mostly used and known for natural language processing tasks. Here it is used for image generation/systhesization. And the authors were able to synthesize images at the resolution of 1024x1024 which is a significant improvement over previous transformer-based method.\n",
    "\n",
    "VQ-GAN is a combination of multiple techniques: transformers, autoencoding, quantization that has proved to be successful in image synthesis tasks. This opens up application in the area beyond text based tasks, such as high resolution image generation. However, the process requires substantial computational resources and powerful hardware for training, including multiple high performance GPUs. This has some limitation for applicability in resource-constrained settings.\n",
    "\n",
    "# VQ-VAE\n",
    "\n",
    "VAE (Variational Autoencoder) belongs to the type of generative models that use deep learning techniques to learn complex data distributions. After learning the data distribution, the mathematics of Bayesian inference is used to generate new sample from that distribution. \n",
    "\n",
    "As any traditional autoencoder architecture, VAE has an encoder. And the underlying philosophy is the same. It inputs datapoints and in the encoding process, it learns a more efficient/representative representation of the dataset. The representation is called latent distribution since it is not directly or trivially observed from the data. The VAE departs from the tradditional auto encoder in that it incorporates probability in its nature. It takes input datapoint and outputs a set of parameters for a conditional probability distribution of the latent variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e979b46f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
